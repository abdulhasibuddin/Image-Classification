{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " CIFAR100_fine_New.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqPP8c_ZcADr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aba804f-9fa0-4c10-8cf2-0e9541cf411f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGWv6nzj31Rw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "8afea436-9745-434c-a245-6dc673283492"
      },
      "source": [
        "#!pip install extra-keras-datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting extra-keras-datasets\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/d1/336998050b8696966b5ecd12188b7bf250eaf9824411b1e1fb4a36f2c47e/extra_keras_datasets-0.1.7.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from extra-keras-datasets) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from extra-keras-datasets) (1.4.1)\n",
            "Building wheels for collected packages: extra-keras-datasets\n",
            "  Building wheel for extra-keras-datasets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for extra-keras-datasets: filename=extra_keras_datasets-0.1.7-cp36-none-any.whl size=7311 sha256=4eccf9e976a6ab53994b40580fdcf51ac95d86223e01de0fd0669539c872dfdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/04/95/e8f214025c2e40d5618a443e4ea09df0031050b35460ea007c\n",
            "Successfully built extra-keras-datasets\n",
            "Installing collected packages: extra-keras-datasets\n",
            "Successfully installed extra-keras-datasets-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KSrUsIPlJxK"
      },
      "source": [
        "work_dir = \"drive/My Drive/Training Records/\"\n",
        "impl_type = \"CNN\"\n",
        "dataset = \"CIFAR100.fine.New\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nH4627DTtnu"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "#os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from extra_keras_datasets import emnist\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler, LambdaCallback\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.callbacks import CSVLogger"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwRTaiwlvMSj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXwh_5yHvM8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769ba802-408c-403a-8241-ada66e51c08b"
      },
      "source": [
        "list_categories_coarse = ['aquatic mammals', 'fish', 'flowers',\t'food containers', 'fruit and vegetables', 'household electrical devices', \n",
        "                          'household furniture', 'insects',\t'large carnivores',\t'large man-made outdoor things', 'large natural outdoor scenes',\n",
        "                          'large omnivores and herbivores',\t'medium-sized mammals',\t'non-insect invertebrates',\t'people', 'reptiles', 'small mammals',\n",
        "                          'trees', 'vehicles 1', 'vehicles 2']\n",
        "\n",
        "list_categories = ['beaver', 'dolphin', 'otter', 'seal', 'whale',\n",
        "                   'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',\n",
        "                   'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',\n",
        "                   'bottles', 'bowls', 'cans', 'cups', 'plates',\n",
        "                   'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',\n",
        "                   'clock', 'computer keyboard', 'lamp', 'telephone', 'television',\n",
        "                   'bed', 'chair', 'couch', 'table', 'wardrobe',\n",
        "                   'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
        "                   'bear', 'leopard', 'lion', 'tiger', 'wolf',\n",
        "                   'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
        "                   'cloud', 'forest', 'mountain', 'plain', 'sea',\n",
        "                   'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
        "                   'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
        "                   'crab', 'lobster', 'snail', 'spider', 'worm',\n",
        "                   'baby', 'boy', 'girl', 'man', 'woman',\n",
        "                   'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',\n",
        "                   'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',\n",
        "                   'maple', 'oak', 'palm', 'pine', 'willow',\n",
        "                   'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train',\n",
        "                   'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
        "                   \n",
        "num_classes = len(list_categories)\n",
        "print('num_classes =', num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_classes = 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQQaW13hXYDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05345db3-08bc-47d3-a977-3cbec6ef0aea"
      },
      "source": [
        "# CIFAR100: Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass \n",
        "# to which it belongs):\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")\n",
        "\n",
        "print('x_train.shape =',x_train.shape)\n",
        "print('y_train.shape =',y_train.shape)\n",
        "print('x_test.shape =',x_test.shape)\n",
        "print('y_test.shape =',y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape = (50000, 32, 32, 3)\n",
            "y_train.shape = (50000, 1)\n",
            "x_test.shape = (10000, 32, 32, 3)\n",
            "y_test.shape = (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoZLACzAFRb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933bb13d-7f49-415d-b0f3-2cd4d042becd"
      },
      "source": [
        "list_encoded_classes = np.unique(y_test)\n",
        "print('len(list_encoded_classes) =', len(list_encoded_classes))\n",
        "print('list_encoded_classes =', list_encoded_classes)\n",
        "\n",
        "if list_encoded_classes[0] > 0:\n",
        "    num_to_sub = list_encoded_classes[0]\n",
        "    print('num_to_sub =', num_to_sub)\n",
        "\n",
        "    list_encoded_classes_new_train = []\n",
        "    for encoded_class in y_train:\n",
        "        list_encoded_classes_new_train.append(encoded_class-num_to_sub)\n",
        "    y_train = np.array(list_encoded_classes_new_train)\n",
        "    \n",
        "    list_encoded_classes_new_test = []\n",
        "    for encoded_class in y_test:\n",
        "        list_encoded_classes_new_test.append(encoded_class-num_to_sub)\n",
        "    y_test = np.array(list_encoded_classes_new_test)\n",
        "\n",
        "print('\\ny_train.shape =',y_train.shape)\n",
        "print('y_test.shape =',y_test.shape)\n",
        "\n",
        "print('\\nlen(np.unique(y_test)) =', len(np.unique(y_test)))\n",
        "print('np.unique(y_test) =', np.unique(y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(list_encoded_classes) = 100\n",
            "list_encoded_classes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97 98 99]\n",
            "\n",
            "y_train.shape = (50000, 1)\n",
            "y_test.shape = (10000, 1)\n",
            "\n",
            "len(np.unique(y_test)) = 100\n",
            "np.unique(y_test) = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97 98 99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woR_39Kvah5y"
      },
      "source": [
        "x_train_norm = x_train/255\n",
        "x_test_norm = x_test/255"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKfm-6z2Z-6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a9a3c5-848d-40aa-d753-49043a3a32d7"
      },
      "source": [
        "final_train_imageset = np.expand_dims(x_train_norm, axis = 4)\n",
        "final_test_imageset = np.expand_dims(x_test_norm, axis = 4)\n",
        "\n",
        "y_train2 = y_train # np.expand_dims(y_train, axis = 1)\n",
        "y_test2 = y_test # np.expand_dims(y_test, axis = 1)\n",
        "\n",
        "print('final_train_imageset.shape =', final_train_imageset.shape)\n",
        "print('final_test_imageset.shape =', final_test_imageset.shape)\n",
        "print('y_train2.shape =', y_train2.shape)\n",
        "print('y_test2.shape =', y_test2.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_train_imageset.shape = (50000, 32, 32, 3, 1)\n",
            "final_test_imageset.shape = (10000, 32, 32, 3, 1)\n",
            "y_train2.shape = (50000, 1)\n",
            "y_test2.shape = (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYQzdAN-baRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e156e5e3-736d-4989-9118-d576db3600e5"
      },
      "source": [
        "final_train_label = tf.keras.utils.to_categorical(y_train2, num_classes)\n",
        "final_test_label = tf.keras.utils.to_categorical(y_test2, num_classes)\n",
        "\n",
        "print('final_train_label.shape =',final_train_label.shape)\n",
        "print('final_test_label.shape =',final_test_label.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_train_label.shape = (50000, 100)\n",
            "final_test_label.shape = (10000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77WXvDHGbavk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3KEYSzNZ_Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b9d2bc-0d00-4474-fcaa-1fc404da52b0"
      },
      "source": [
        "NUM_NEURONS = 256\n",
        "NUM_LAYERS = 10\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 30\n",
        "#epochs_completed = 0\n",
        "LEARNING_RATE = 0.0001\n",
        "EPSILON = 1e-4\n",
        "DROPOUT = 0.5\n",
        "\n",
        "LOSS = 'categorical_crossentropy'\n",
        "ACTIVATION_FUNCTION = 'relu'\n",
        "FINAL_ACTIVATION_FUNCTION = 'softmax'\n",
        "validation_split = 0.1\n",
        "kernel_size=(1,1)\n",
        "early_stop_after_epochs = 50\n",
        "\n",
        "nTry = \"2\"\n",
        "# +\"_kernel\"+str(kernel_size)+\"_lr\"+str(LEARNING_RATE)+\"_batch\"+str(BATCH_SIZE)+\"_epochs\"+str(NUM_EPOCHS)\n",
        "#checkpointer_name  = \"weights_\"+dataset+\"_\"+impl_type+\"_nLayers\"+str(NUM_LAYERS)+\"_nNeurons\"+str(NUM_NEURONS)+\"_dropout\"+str(DROPOUT)+\"_batch\"+str(BATCH_SIZE)+\".hdf5\"\n",
        "checkpointer_name  = \"weights.\"+dataset+\".\"+impl_type+\".batch\"+str(BATCH_SIZE)+\".nTry.\"+nTry\n",
        "log_name = \"log.\"+checkpointer_name[8:]+\".log\"\n",
        "\n",
        "print('checkpointer_name =', checkpointer_name)\n",
        "print('log_name =', log_name)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpointer_name = weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "log_name = log.CIFAR100.fine.New.CNN.batch32.nTry.2.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n02hlBxFXYMC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-XbkH-AXYR3"
      },
      "source": [
        "'''\n",
        "input_shape = final_train_imageset.shape[1:]\n",
        "\n",
        "# Input tensor shape\n",
        "inputs = Input(input_shape)\n",
        "#x = MaxPooling2D(pool_size=(3,3), strides=(1,1))\n",
        "\n",
        "x = Conv2D(64, kernel_size=(3,3))(inputs)\n",
        "x = Dropout(DROPOUT)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "outputs = Dense(num_classes, activation=FINAL_ACTIVATION_FUNCTION)(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vVsy18FVTHu",
        "outputId": "639a4421-81ca-4df3-d41a-072f4004cb46"
      },
      "source": [
        "pad = 25\n",
        "\n",
        "input_shape = final_train_imageset.shape[1:]\n",
        "\n",
        "# Input tensor shape\n",
        "inputs = Input(input_shape)\n",
        "x = ZeroPadding3D(padding=(pad,pad,pad))(inputs)\n",
        "\n",
        "x = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "#x = Dropout(DROPOUT)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(num_classes, activation=FINAL_ACTIVATION_FUNCTION)(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3, 1)]    0         \n",
            "_________________________________________________________________\n",
            "zero_padding3d (ZeroPadding3 (None, 82, 82, 53, 1)     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 82, 80, 51, 32)    320       \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 41, 40, 25, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 41, 38, 23, 64)    18496     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 20, 19, 11, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 17, 9, 64)     36928     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 10, 8, 4, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 6, 2, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 5, 3, 1, 64)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               492032    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               51300     \n",
            "=================================================================\n",
            "Total params: 636,004\n",
            "Trainable params: 636,004\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpPj5pKyULzE"
      },
      "source": [
        "'''\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=final_train_imageset.shape[1:]),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation=FINAL_ACTIVATION_FUNCTION)\n",
        "])\n",
        "model.summary()\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2c0PlPPUNCx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu7jBKYUXYaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210ced5b-bac2-4867-c65c-8d2c2409bd81"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr = LEARNING_RATE, epsilon=EPSILON)\n",
        "model.compile(\n",
        "    optimizer=optimizer, #'rmsprop',\n",
        "    loss=LOSS,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENSmBglrXYlp"
      },
      "source": [
        "# save the best model with least validation loss\n",
        "checkpointer = ModelCheckpoint(filepath = work_dir+checkpointer_name, \n",
        "                               #monitor='val_accuracy',\n",
        "                               monitor='val_loss',\n",
        "                               save_weights_only=False,  \n",
        "                               mode='auto', \n",
        "                               verbose = 0, \n",
        "                               save_best_only =False\n",
        "                               )\n",
        "checkpointer_best = ModelCheckpoint(filepath = work_dir+\"best_\"+checkpointer_name, \n",
        "                                    monitor='val_loss', \n",
        "                                    save_weights_only=False,\n",
        "                                    mode='auto',  \n",
        "                                    verbose = 1, \n",
        "                                    save_best_only = True\n",
        "                                    )\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=early_stop_after_epochs)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_LQHQpAdX-U"
      },
      "source": [
        "def checkBestPerformance(epoch, logs):\n",
        "    log_data = pd.read_csv(work_dir+log_name, sep=',', usecols=['val_loss', 'val_accuracy'], engine='python')\n",
        "    min_val_loss = min(log_data.val_loss.values)\n",
        "    max_val_acc = max(log_data.val_accuracy.values)\n",
        "\n",
        "    current_val_acc = logs['val_accuracy']\n",
        "    current_val_loss = logs['val_loss']\n",
        "\n",
        "    save_filepath = work_dir+\"best_\"+checkpointer_name\n",
        "    if current_val_loss < min_val_loss:\n",
        "        model.save(filepath = save_filepath)\n",
        "        print(\"\\nval_loss decreased from\", min_val_loss, \"to\", current_val_loss, \".\")\n",
        "\n",
        "        #list_callbacks = [checkpointer, checkpointer_best, csv_logger, early_stopping]\n",
        "        #print(\"\\nReturned to previous best checkpoint callback.\")\n",
        "\n",
        "    elif (current_val_loss==min_val_loss) and (current_val_acc>max_val_acc):\n",
        "        model.save(filepath = save_filepath)\n",
        "        print(\"\\nval_accuracy increased from\", max_val_acc, \"to\", current_val_acc, \".\")\n",
        "\n",
        "        #list_callbacks = [checkpointer, checkpointer_best, csv_logger, early_stopping]\n",
        "        #print(\"\\nReturned to previous best checkpoint callback.\")\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "        #print(\"\\nPerformance did not improve from existing min_val_loss =\", min_val_loss, \", max_val_acc =\", max_val_acc, \".\")\n",
        "    #return"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYDse9cTyOvk"
      },
      "source": [
        "epochs_completed = 0\n",
        "csv_logger = CSVLogger(work_dir+log_name, separator=',', append=True)\n",
        "\n",
        "try:\n",
        "    log_data = pd.read_csv(work_dir+log_name, sep=',', usecols=['epoch'], engine='python')\n",
        "    epochs_completed = log_data.shape[0]\n",
        "\n",
        "    if epochs_completed > 0:\n",
        "        model = load_model(work_dir+checkpointer_name)\n",
        "        list_callbacks = [checkpointer, LambdaCallback(on_epoch_end=checkBestPerformance), csv_logger, early_stopping]\n",
        "        print(\"epochs_completed =\", epochs_completed)\n",
        "except:\n",
        "    list_callbacks = [checkpointer, checkpointer_best, csv_logger, early_stopping]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1jON3KWXYi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ac4807-9322-4fd1-d763-37bfb371b1ec"
      },
      "source": [
        "print(\"Previously completed epochs =\", epochs_completed, \"\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(final_train_imageset, final_train_label, \n",
        "                    shuffle=True, \n",
        "                    batch_size = BATCH_SIZE, \n",
        "                    epochs = NUM_EPOCHS - epochs_completed, \n",
        "                    #steps_per_epoch = 2,\n",
        "                    validation_split = validation_split, \n",
        "                    #validation_data = (final_test_imageset, final_test_label),\n",
        "                    callbacks=list_callbacks\n",
        "                    )\n",
        "elapsed_time = time.time() - start_time \n",
        "print(\"\\nTime elapsed: \", elapsed_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Previously completed epochs = 0 \n",
            "\n",
            "Epoch 1/30\n",
            "1407/1407 [==============================] - 220s 154ms/step - loss: 4.3975 - accuracy: 0.0352 - val_loss: 4.1800 - val_accuracy: 0.0648\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.17997, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 2/30\n",
            "1407/1407 [==============================] - 216s 154ms/step - loss: 4.0065 - accuracy: 0.0843 - val_loss: 3.9158 - val_accuracy: 0.1052\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.17997 to 3.91583, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 3/30\n",
            "1407/1407 [==============================] - 216s 154ms/step - loss: 3.7824 - accuracy: 0.1217 - val_loss: 3.7511 - val_accuracy: 0.1272\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.91583 to 3.75106, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 4/30\n",
            "1407/1407 [==============================] - 216s 154ms/step - loss: 3.6184 - accuracy: 0.1512 - val_loss: 3.6318 - val_accuracy: 0.1446\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.75106 to 3.63179, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 5/30\n",
            "1407/1407 [==============================] - 216s 154ms/step - loss: 3.4984 - accuracy: 0.1716 - val_loss: 3.5499 - val_accuracy: 0.1610\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.63179 to 3.54989, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 6/30\n",
            "1407/1407 [==============================] - 216s 154ms/step - loss: 3.3927 - accuracy: 0.1910 - val_loss: 3.4662 - val_accuracy: 0.1812\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.54989 to 3.46619, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 7/30\n",
            "1407/1407 [==============================] - 216s 154ms/step - loss: 3.2920 - accuracy: 0.2115 - val_loss: 3.3839 - val_accuracy: 0.1990\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.46619 to 3.38394, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 8/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 3.1976 - accuracy: 0.2269 - val_loss: 3.3306 - val_accuracy: 0.2074\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.38394 to 3.33060, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 9/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 3.1095 - accuracy: 0.2436 - val_loss: 3.1891 - val_accuracy: 0.2312\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00009: val_loss improved from 3.33060 to 3.18911, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 10/30\n",
            "1407/1407 [==============================] - 216s 154ms/step - loss: 3.0281 - accuracy: 0.2577 - val_loss: 3.2427 - val_accuracy: 0.2256\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 3.18911\n",
            "Epoch 11/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 2.9550 - accuracy: 0.2716 - val_loss: 3.1141 - val_accuracy: 0.2504\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00011: val_loss improved from 3.18911 to 3.11415, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 12/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 2.8861 - accuracy: 0.2852 - val_loss: 3.0570 - val_accuracy: 0.2570\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00012: val_loss improved from 3.11415 to 3.05705, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 13/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 2.8201 - accuracy: 0.3004 - val_loss: 3.0147 - val_accuracy: 0.2618\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00013: val_loss improved from 3.05705 to 3.01468, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 14/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 2.7622 - accuracy: 0.3110 - val_loss: 2.9460 - val_accuracy: 0.2782\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00014: val_loss improved from 3.01468 to 2.94595, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 15/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 2.7071 - accuracy: 0.3201 - val_loss: 2.9525 - val_accuracy: 0.2726\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 2.94595\n",
            "Epoch 16/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 2.6525 - accuracy: 0.3318 - val_loss: 2.9307 - val_accuracy: 0.2774\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00016: val_loss improved from 2.94595 to 2.93067, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 17/30\n",
            "1407/1407 [==============================] - 217s 154ms/step - loss: 2.6032 - accuracy: 0.3415 - val_loss: 2.9301 - val_accuracy: 0.2884\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "\n",
            "Epoch 00017: val_loss improved from 2.93067 to 2.93005, saving model to drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2\n",
            "INFO:tensorflow:Assets written to: drive/My Drive/Training Records/best_weights.CIFAR100.fine.New.CNN.batch32.nTry.2/assets\n",
            "Epoch 18/30\n",
            "1177/1407 [========================>.....] - ETA: 34s - loss: 2.5563 - accuracy: 0.3510"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbumzY9bXYgX"
      },
      "source": [
        "result = model.evaluate(final_test_imageset, final_test_label)\n",
        "print(\"Accuracy : {}, Loss: {}\".format(result[1], result[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD_4XS5Iiv0b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJy4LjXai31L"
      },
      "source": [
        "'''\n",
        "NUM_NEURONS = 64\n",
        "NUM_LAYERS = 3\n",
        "DROPOUT = 0.5\n",
        "checkpointer_name  = \"weights_\"+dataset+\"_\"+impl_type+\"_nLayers\"+str(NUM_LAYERS)+\"_nNeurons\"+str(NUM_NEURONS)+\"_dropout\"+str(DROPOUT)+\".hdf5\"\n",
        "log_name = \"log_\"+checkpointer_name[8:-5]+\".log\"\n",
        "log_data = pd.read_csv(work_dir+log_name, sep=',', engine='python') \n",
        "print('log_name =', log_name)\n",
        "#'''\n",
        "\n",
        "model_loaded = load_model(work_dir+\"best_\"+checkpointer_name)\n",
        "print(\"Loaded \"+work_dir+\"best_\"+checkpointer_name+\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBUe76_NlFi-"
      },
      "source": [
        "'''\n",
        "Record: \n",
        "EMNIST-Digit: AlexNet = 99.21, CapsuleNet = 99.37, VGGNet = 99.62, ResNet = 99.63, ma2019 = 99.75;\n",
        "---\n",
        "\n",
        "#'''\n",
        "\n",
        "result2 = model_loaded.evaluate(final_test_imageset, final_test_label)\n",
        "print(\"nLayers: {}, nNeurons: {}, DROPOUT: {}, Test Acc: {}, Test Loss: {}\".format(NUM_LAYERS, NUM_NEURONS, DROPOUT, round(result2[1], 4), round(result2[0], 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc7lBQw9zE-Y"
      },
      "source": [
        "#elapsed_time = 13273.57\n",
        "\n",
        "with open(work_dir+'Records.csv', \"a\") as fp:\n",
        "    wr = csv.writer(fp, dialect='excel')\n",
        "    wr.writerow([checkpointer_name[8:-5], round(result2[1], 4), round(result2[0], 4), elapsed_time])\n",
        "print(\"Saved results.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I69Rz7U0lz2R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNrrlrUTXYVp"
      },
      "source": [
        "#Confution Matrix and Classification Report\n",
        "Y_pred = model_loaded.predict_generator(final_test_imageset, len(final_test_imageset))\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhiUB_uNXYPL"
      },
      "source": [
        "# Precision [TP/TP+FP] = The ratio of correctly predicted positive observations to the total predicted positive observations.\n",
        "# Recall (Sensitivity) [TP/TP+FN] = The ratio of correctly predicted positive observations to the all observations in actual class - 'yes'.\n",
        "# F1 score [F1 Score = 2*(Recall * Precision) / (Recall + Precision)] = The weighted average of Precision and Recall.\n",
        "# Support = The number of samples of the true response that lie in that class.\n",
        "print('Classification Report:')\n",
        "#target_names = ['Mono', 'Di'] # not ['Di', 'Mono']\n",
        "print(classification_report(y_test, y_pred)) #, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7adZ1XniXYKV"
      },
      "source": [
        "print('Classification Report')\n",
        "print(classification_report(y_test, y_pred, target_names=list_categories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2woc7B6ClV6G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJjvgOHfkREd"
      },
      "source": [
        "log_data = pd.read_csv(work_dir+log_name, sep=',', engine='python') \n",
        "log_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXvYwRP6lWQz"
      },
      "source": [
        "# Getting the model history keys \n",
        "#history.history.keys()\n",
        "log_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DyZbASblWNn"
      },
      "source": [
        "# plot the training artifacts\n",
        "title = \"Val loss for \"+dataset+\" \"+impl_type+\" (\"+str(NUM_LAYERS)+\" layers, \"+str(NUM_NEURONS)+\" neurons)\"\n",
        "\n",
        "plt.plot(log_data['loss'])\n",
        "plt.plot(log_data['val_loss'])\n",
        "plt.title(title)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss','val_loss'], loc = 'best')\n",
        "\n",
        "img_path = work_dir+'Images/vLoss_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "plt.show()\n",
        "print('img_path =', img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIPNBC_slWKi"
      },
      "source": [
        "title = \"Val acc for \"+dataset+\" \"+impl_type+\" (\"+str(NUM_LAYERS)+\" layers, \"+str(NUM_NEURONS)+\" neurons)\"\n",
        "\n",
        "plt.plot(log_data['accuracy'])\n",
        "plt.plot(log_data['val_accuracy'])\n",
        "plt.title(title)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy','val_accuracy'], loc = 'best')\n",
        "\n",
        "img_path = work_dir+'Images/vAcc_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "plt.show()\n",
        "print('img_path =', img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wxpuYhJlWHI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHcBPAZMlWDz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDC-KGCR9KXu"
      },
      "source": [
        "Image ckeck:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jg6TBJxlV_b"
      },
      "source": [
        "'''\n",
        "Record:\n",
        "EMNIST-Digit: AlexNet = 99.21, VGGNet = 99.62, ResNet = 99.63, CapsuleNet = 99.37, ma2019 = 99.75;\n",
        "dropout = 0.0, Test Acc = 0., Test Loss = 0.;\n",
        "dropout = 0.2, Test Acc = 0.9959, Test Loss = 0.0328;\n",
        "dropout = 0.5, Test Acc = 0.9954, Test Loss = 0.0313;\n",
        "#'''\n",
        "\n",
        "'''\n",
        "DROPOUT = 0.5\n",
        "checkpointer_name  = \"weights_\"+dataset+\"_\"+impl_type+\"_nLayers\"+str(NUM_LAYERS)+\"_nNeurons\"+str(NUM_NEURONS)+\"_dropout\"+str(DROPOUT)+\".hdf5\"\n",
        "log_name = \"log_\"+checkpointer_name[8:-5]+\".log\"\n",
        "log_data = pd.read_csv(work_dir+log_name, sep=',', engine='python') \n",
        "print('log_name =', log_name)\n",
        "###\n",
        "\n",
        "title = \"Val loss for \"+dataset+\" \"+impl_type+\" (\"+str(NUM_LAYERS)+\" layers, \"+str(NUM_NEURONS)+\" neurons)\"\n",
        "plt.plot(log_data['loss'])\n",
        "plt.plot(log_data['val_loss'])\n",
        "plt.title(title)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss','val_loss'], loc = 'best')\n",
        "plt.show()\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQlafPWlXYH5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}