{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR100_fine_New_FOIU2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqPP8c_ZcADr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6bf927-e391-49b9-aa5d-4e8652e960f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGWv6nzj31Rw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "8afea436-9745-434c-a245-6dc673283492"
      },
      "source": [
        "#!pip install extra-keras-datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting extra-keras-datasets\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/d1/336998050b8696966b5ecd12188b7bf250eaf9824411b1e1fb4a36f2c47e/extra_keras_datasets-0.1.7.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from extra-keras-datasets) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from extra-keras-datasets) (1.4.1)\n",
            "Building wheels for collected packages: extra-keras-datasets\n",
            "  Building wheel for extra-keras-datasets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for extra-keras-datasets: filename=extra_keras_datasets-0.1.7-cp36-none-any.whl size=7311 sha256=4eccf9e976a6ab53994b40580fdcf51ac95d86223e01de0fd0669539c872dfdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/04/95/e8f214025c2e40d5618a443e4ea09df0031050b35460ea007c\n",
            "Successfully built extra-keras-datasets\n",
            "Installing collected packages: extra-keras-datasets\n",
            "Successfully installed extra-keras-datasets-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KSrUsIPlJxK"
      },
      "source": [
        "work_dir = \"drive/My Drive/Training Records/\"\n",
        "impl_type = \"CNN\"\n",
        "dataset = \"CIFAR100.fine.New.FOIU2\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nH4627DTtnu"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "#os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from extra_keras_datasets import emnist\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler, LambdaCallback\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.callbacks import CSVLogger"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwRTaiwlvMSj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXwh_5yHvM8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27b18ee-56c6-41d8-c009-9046db6ca550"
      },
      "source": [
        "list_categories_coarse = ['aquatic mammals', 'fish', 'flowers',\t'food containers', 'fruit and vegetables', 'household electrical devices', \n",
        "                          'household furniture', 'insects',\t'large carnivores',\t'large man-made outdoor things', 'large natural outdoor scenes',\n",
        "                          'large omnivores and herbivores',\t'medium-sized mammals',\t'non-insect invertebrates',\t'people', 'reptiles', 'small mammals',\n",
        "                          'trees', 'vehicles 1', 'vehicles 2']\n",
        "\n",
        "list_categories = ['beaver', 'dolphin', 'otter', 'seal', 'whale',\n",
        "                   'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',\n",
        "                   'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',\n",
        "                   'bottles', 'bowls', 'cans', 'cups', 'plates',\n",
        "                   'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',\n",
        "                   'clock', 'computer keyboard', 'lamp', 'telephone', 'television',\n",
        "                   'bed', 'chair', 'couch', 'table', 'wardrobe',\n",
        "                   'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
        "                   'bear', 'leopard', 'lion', 'tiger', 'wolf',\n",
        "                   'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
        "                   'cloud', 'forest', 'mountain', 'plain', 'sea',\n",
        "                   'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
        "                   'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
        "                   'crab', 'lobster', 'snail', 'spider', 'worm',\n",
        "                   'baby', 'boy', 'girl', 'man', 'woman',\n",
        "                   'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',\n",
        "                   'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',\n",
        "                   'maple', 'oak', 'palm', 'pine', 'willow',\n",
        "                   'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train',\n",
        "                   'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
        "                   \n",
        "num_classes = len(list_categories)\n",
        "print('num_classes =', num_classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_classes = 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQQaW13hXYDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222882f3-46b1-42ff-df2b-42e16f42297e"
      },
      "source": [
        "# CIFAR100: Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass \n",
        "# to which it belongs):\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")\n",
        "\n",
        "print('x_train.shape =',x_train.shape)\n",
        "print('y_train.shape =',y_train.shape)\n",
        "print('x_test.shape =',x_test.shape)\n",
        "print('y_test.shape =',y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape = (50000, 32, 32, 3)\n",
            "y_train.shape = (50000, 1)\n",
            "x_test.shape = (10000, 32, 32, 3)\n",
            "y_test.shape = (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoZLACzAFRb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf37dbaf-5561-4437-bcb2-86359c7f397a"
      },
      "source": [
        "list_encoded_classes = np.unique(y_test)\n",
        "print('len(list_encoded_classes) =', len(list_encoded_classes))\n",
        "print('list_encoded_classes =', list_encoded_classes)\n",
        "\n",
        "if list_encoded_classes[0] > 0:\n",
        "    num_to_sub = list_encoded_classes[0]\n",
        "    print('num_to_sub =', num_to_sub)\n",
        "\n",
        "    list_encoded_classes_new_train = []\n",
        "    for encoded_class in y_train:\n",
        "        list_encoded_classes_new_train.append(encoded_class-num_to_sub)\n",
        "    y_train = np.array(list_encoded_classes_new_train)\n",
        "    \n",
        "    list_encoded_classes_new_test = []\n",
        "    for encoded_class in y_test:\n",
        "        list_encoded_classes_new_test.append(encoded_class-num_to_sub)\n",
        "    y_test = np.array(list_encoded_classes_new_test)\n",
        "\n",
        "print('\\ny_train.shape =',y_train.shape)\n",
        "print('y_test.shape =',y_test.shape)\n",
        "\n",
        "print('\\nlen(np.unique(y_test)) =', len(np.unique(y_test)))\n",
        "print('np.unique(y_test) =', np.unique(y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(list_encoded_classes) = 100\n",
            "list_encoded_classes = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97 98 99]\n",
            "\n",
            "y_train.shape = (50000, 1)\n",
            "y_test.shape = (10000, 1)\n",
            "\n",
            "len(np.unique(y_test)) = 100\n",
            "np.unique(y_test) = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97 98 99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woR_39Kvah5y"
      },
      "source": [
        "x_train_norm = x_train/255\n",
        "x_test_norm = x_test/255"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKfm-6z2Z-6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb35b36b-0c4a-4b98-e9ab-cad2fe7ad195"
      },
      "source": [
        "final_train_imageset = np.expand_dims(x_train_norm, axis = 4)\n",
        "final_test_imageset = np.expand_dims(x_test_norm, axis = 4)\n",
        "\n",
        "y_train2 = y_train # np.expand_dims(y_train, axis = 1)\n",
        "y_test2 = y_test # np.expand_dims(y_test, axis = 1)\n",
        "\n",
        "print('final_train_imageset.shape =', final_train_imageset.shape)\n",
        "print('final_test_imageset.shape =', final_test_imageset.shape)\n",
        "print('y_train2.shape =', y_train2.shape)\n",
        "print('y_test2.shape =', y_test2.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_train_imageset.shape = (50000, 32, 32, 3, 1)\n",
            "final_test_imageset.shape = (10000, 32, 32, 3, 1)\n",
            "y_train2.shape = (50000, 1)\n",
            "y_test2.shape = (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYQzdAN-baRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d17e7f6-035b-400a-88d5-bd53fa804813"
      },
      "source": [
        "final_train_label = tf.keras.utils.to_categorical(y_train2, num_classes)\n",
        "final_test_label = tf.keras.utils.to_categorical(y_test2, num_classes)\n",
        "\n",
        "print('final_train_label.shape =',final_train_label.shape)\n",
        "print('final_test_label.shape =',final_test_label.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_train_label.shape = (50000, 100)\n",
            "final_test_label.shape = (10000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77WXvDHGbavk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3KEYSzNZ_Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85264810-d409-42c5-e45f-4d34561b1b89"
      },
      "source": [
        "NUM_NEURONS = 256\n",
        "NUM_LAYERS = 10\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 30\n",
        "#epochs_completed = 0\n",
        "LEARNING_RATE = 0.0001\n",
        "EPSILON = 1e-4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "LOSS = 'categorical_crossentropy'\n",
        "ACTIVATION_FUNCTION = 'relu'\n",
        "FINAL_ACTIVATION_FUNCTION = 'softmax'\n",
        "validation_split = 0.1\n",
        "kernel_size=(1,1)\n",
        "early_stop_after_epochs = 50\n",
        "\n",
        "nTry = \"1\"\n",
        "# +\"_kernel\"+str(kernel_size)+\"_lr\"+str(LEARNING_RATE)+\"_batch\"+str(BATCH_SIZE)+\"_epochs\"+str(NUM_EPOCHS)\n",
        "#checkpointer_name  = \"weights_\"+dataset+\"_\"+impl_type+\"_nLayers\"+str(NUM_LAYERS)+\"_nNeurons\"+str(NUM_NEURONS)+\"_dropout\"+str(DROPOUT)+\"_batch\"+str(BATCH_SIZE)+\".hdf5\"\n",
        "checkpointer_name  = \"weights.\"+dataset+\".\"+impl_type+\".batch\"+str(BATCH_SIZE)+\".nTry.\"+nTry\n",
        "log_name = \"log.\"+checkpointer_name[8:]+\".log\"\n",
        "\n",
        "print('checkpointer_name =', checkpointer_name)\n",
        "print('log_name =', log_name)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpointer_name = weights.CIFAR100.fine.New.FOIU2.CNN.batch32.nTry.1\n",
            "log_name = log.CIFAR100.fine.New.FOIU2.CNN.batch32.nTry.1.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n02hlBxFXYMC"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-XbkH-AXYR3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "10026651-95ae-4e91-8425-db80c2ed4812"
      },
      "source": [
        "'''\n",
        "input_shape = final_train_imageset.shape[1:]\n",
        "\n",
        "# Input tensor shape\n",
        "inputs = Input(input_shape)\n",
        "#x = MaxPooling2D(pool_size=(3,3), strides=(1,1))\n",
        "\n",
        "x = Conv2D(64, kernel_size=(3,3))(inputs)\n",
        "x = Dropout(DROPOUT)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "outputs = Dense(num_classes, activation=FINAL_ACTIVATION_FUNCTION)(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "#'''"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ninput_shape = final_train_imageset.shape[1:]\\n\\n# Input tensor shape\\ninputs = Input(input_shape)\\n#x = MaxPooling2D(pool_size=(3,3), strides=(1,1))\\n\\nx = Conv2D(64, kernel_size=(3,3))(inputs)\\nx = Dropout(DROPOUT)(x)\\n\\nx = Flatten()(x)\\noutputs = Dense(num_classes, activation=FINAL_ACTIVATION_FUNCTION)(x)\\n\\nmodel = Model(inputs=inputs, outputs=outputs)\\nmodel.summary()\\n#'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "0vVsy18FVTHu",
        "outputId": "51f9db2a-b846-4906-9daa-7cd941bc13c6"
      },
      "source": [
        "'''\n",
        "#####\n",
        "up_size = 16\n",
        "\n",
        "input_shape = final_train_imageset.shape[1:]\n",
        "inputs = Input(input_shape)\n",
        "x = UpSampling3D(size=(up_size, up_size, up_size))(inputs)\n",
        "\n",
        "x = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Dropout(DROPOUT)(x)\n",
        "#####\n",
        "\n",
        "up_size = 46\n",
        "x = UpSampling3D(size=(up_size, up_size, up_size))(x)\n",
        "\n",
        "x = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "x = Dropout(DROPOUT)(x)\n",
        "#####\n",
        "\n",
        "x = Flatten()(x)\n",
        "#x = Dense(256, activation='relu')(x)\n",
        "outputs = Dense(num_classes, activation=FINAL_ACTIVATION_FUNCTION)(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "#'''"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#####\\nup_size = 16\\n\\ninput_shape = final_train_imageset.shape[1:]\\ninputs = Input(input_shape)\\nx = UpSampling3D(size=(up_size, up_size, up_size))(inputs)\\n\\nx = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\\nx = MaxPool3D(pool_size=(2, 2, 2))(x)\\nx = Conv2D(64, (3,3), activation='relu')(x)\\nx = MaxPool3D(pool_size=(2, 2, 2))(x)\\nx = Conv2D(64, (3,3), activation='relu')(x)\\nx = MaxPool3D(pool_size=(2, 2, 2))(x)\\nx = Conv2D(64, (3,3), activation='relu')(x)\\nx = MaxPool3D(pool_size=(2, 2, 2))(x)\\nx = Dropout(DROPOUT)(x)\\n#####\\n\\nup_size = 46\\nx = UpSampling3D(size=(up_size, up_size, up_size))(x)\\n\\nx = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\\nx = MaxPool3D(pool_size=(2, 2, 2))(x)\\nx = Conv2D(64, (3,3), activation='relu')(x)\\nx = MaxPool3D(pool_size=(2, 2, 2))(x)\\nx = Conv2D(64, (3,3), activation='relu')(x)\\nx = MaxPool3D(pool_size=(2, 2, 2))(x)\\nx = Conv2D(64, (3,3), activation='relu')(x)\\nx = MaxPool3D(pool_size=(2, 2, 2))(x)\\nx = Dropout(DROPOUT)(x)\\n#####\\n\\nx = Flatten()(x)\\n#x = Dense(256, activation='relu')(x)\\noutputs = Dense(num_classes, activation=FINAL_ACTIVATION_FUNCTION)(x)\\n\\nmodel = Model(inputs=inputs, outputs=outputs)\\nmodel.summary()\\n#\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpPj5pKyULzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f607bb-6d98-4ecf-803b-9bce22f85cf2"
      },
      "source": [
        "#'''\n",
        "input_shape = final_train_imageset.shape[1:]\n",
        "inputs = Input(input_shape)\n",
        "x = inputs\n",
        "\n",
        "up_size = 2\n",
        "x = UpSampling3D(size=(up_size, up_size, up_size))(x)\n",
        "x = Conv2D(32, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "\n",
        "up_size = 2\n",
        "x = UpSampling3D(size=(up_size, up_size, up_size))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "\n",
        "up_size = 4\n",
        "x = UpSampling3D(size=(up_size, up_size, up_size))(x)\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
        "\n",
        "x = Dropout(DROPOUT)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "#x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(num_classes, activation=FINAL_ACTIVATION_FUNCTION)(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "#'''"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 32, 32, 3, 1)]    0         \n",
            "_________________________________________________________________\n",
            "up_sampling3d_36 (UpSampling (None, 64, 64, 6, 1)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 64, 62, 4, 32)     320       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_67 (MaxPooling (None, 32, 31, 2, 32)     0         \n",
            "_________________________________________________________________\n",
            "up_sampling3d_37 (UpSampling (None, 64, 62, 4, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 64, 60, 2, 64)     18496     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_68 (MaxPooling (None, 32, 30, 1, 64)     0         \n",
            "_________________________________________________________________\n",
            "up_sampling3d_38 (UpSampling (None, 128, 120, 4, 64)   0         \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 128, 118, 2, 64)   36928     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_69 (MaxPooling (None, 64, 59, 1, 64)     0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64, 59, 1, 64)     0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 241664)            0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               24166500  \n",
            "=================================================================\n",
            "Total params: 24,222,244\n",
            "Trainable params: 24,222,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2c0PlPPUNCx"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu7jBKYUXYaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ace3dcb-d70b-4320-d3c6-d7c327c143d1"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr = LEARNING_RATE, epsilon=EPSILON)\n",
        "model.compile(\n",
        "    optimizer=optimizer, #'rmsprop',\n",
        "    loss=LOSS,\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENSmBglrXYlp"
      },
      "source": [
        "# save the best model with least validation loss\n",
        "checkpointer = ModelCheckpoint(filepath = work_dir+checkpointer_name, \n",
        "                               #monitor='val_accuracy',\n",
        "                               monitor='val_loss',\n",
        "                               save_weights_only=False,  \n",
        "                               mode='auto', \n",
        "                               verbose = 0, \n",
        "                               save_best_only =False\n",
        "                               )\n",
        "checkpointer_best = ModelCheckpoint(filepath = work_dir+\"best_\"+checkpointer_name, \n",
        "                                    monitor='val_loss', \n",
        "                                    save_weights_only=False,\n",
        "                                    mode='auto',  \n",
        "                                    verbose = 1, \n",
        "                                    save_best_only = True\n",
        "                                    )\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=early_stop_after_epochs)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_LQHQpAdX-U"
      },
      "source": [
        "def checkBestPerformance(epoch, logs):\n",
        "    log_data = pd.read_csv(work_dir+log_name, sep=',', usecols=['val_loss', 'val_accuracy'], engine='python')\n",
        "    min_val_loss = min(log_data.val_loss.values)\n",
        "    max_val_acc = max(log_data.val_accuracy.values)\n",
        "\n",
        "    current_val_acc = logs['val_accuracy']\n",
        "    current_val_loss = logs['val_loss']\n",
        "\n",
        "    save_filepath = work_dir+\"best_\"+checkpointer_name\n",
        "    if current_val_loss < min_val_loss:\n",
        "        model.save(filepath = save_filepath)\n",
        "        print(\"\\nval_loss decreased from\", min_val_loss, \"to\", current_val_loss, \".\")\n",
        "\n",
        "        #list_callbacks = [checkpointer, checkpointer_best, csv_logger, early_stopping]\n",
        "        #print(\"\\nReturned to previous best checkpoint callback.\")\n",
        "\n",
        "    elif (current_val_loss==min_val_loss) and (current_val_acc>max_val_acc):\n",
        "        model.save(filepath = save_filepath)\n",
        "        print(\"\\nval_accuracy increased from\", max_val_acc, \"to\", current_val_acc, \".\")\n",
        "\n",
        "        #list_callbacks = [checkpointer, checkpointer_best, csv_logger, early_stopping]\n",
        "        #print(\"\\nReturned to previous best checkpoint callback.\")\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "        #print(\"\\nPerformance did not improve from existing min_val_loss =\", min_val_loss, \", max_val_acc =\", max_val_acc, \".\")\n",
        "    #return"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYDse9cTyOvk"
      },
      "source": [
        "epochs_completed = 0\n",
        "csv_logger = CSVLogger(work_dir+log_name, separator=',', append=True)\n",
        "\n",
        "try:\n",
        "    log_data = pd.read_csv(work_dir+log_name, sep=',', usecols=['epoch'], engine='python')\n",
        "    epochs_completed = log_data.shape[0]\n",
        "\n",
        "    if epochs_completed > 0:\n",
        "        model = load_model(work_dir+checkpointer_name)\n",
        "        list_callbacks = [checkpointer, LambdaCallback(on_epoch_end=checkBestPerformance), csv_logger, early_stopping]\n",
        "        print(\"epochs_completed =\", epochs_completed)\n",
        "except:\n",
        "    list_callbacks = [checkpointer, checkpointer_best, csv_logger, early_stopping]"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1jON3KWXYi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7935a3-4e3c-4b0c-8886-167d971e5d40"
      },
      "source": [
        "print(\"Previously completed epochs =\", epochs_completed, \"\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(final_train_imageset, final_train_label, \n",
        "                    shuffle=True, \n",
        "                    batch_size = BATCH_SIZE, \n",
        "                    epochs = NUM_EPOCHS - epochs_completed, \n",
        "                    #steps_per_epoch = 2,\n",
        "                    validation_split = validation_split, \n",
        "                    #validation_data = (final_test_imageset, final_test_label),\n",
        "                    callbacks=list_callbacks\n",
        "                    )\n",
        "elapsed_time = time.time() - start_time \n",
        "print(\"\\nTime elapsed: \", elapsed_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Previously completed epochs = 0 \n",
            "\n",
            "Epoch 1/30\n",
            " 258/1407 [====>.........................] - ETA: 3:28 - loss: 4.2682 - accuracy: 0.0592"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbumzY9bXYgX"
      },
      "source": [
        "result = model.evaluate(final_test_imageset, final_test_label)\n",
        "print(\"Accuracy : {}, Loss: {}\".format(result[1], result[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD_4XS5Iiv0b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJy4LjXai31L"
      },
      "source": [
        "'''\n",
        "NUM_NEURONS = 64\n",
        "NUM_LAYERS = 3\n",
        "DROPOUT = 0.5\n",
        "checkpointer_name  = \"weights_\"+dataset+\"_\"+impl_type+\"_nLayers\"+str(NUM_LAYERS)+\"_nNeurons\"+str(NUM_NEURONS)+\"_dropout\"+str(DROPOUT)+\".hdf5\"\n",
        "log_name = \"log_\"+checkpointer_name[8:-5]+\".log\"\n",
        "log_data = pd.read_csv(work_dir+log_name, sep=',', engine='python') \n",
        "print('log_name =', log_name)\n",
        "#'''\n",
        "\n",
        "model_loaded = load_model(work_dir+\"best_\"+checkpointer_name)\n",
        "print(\"Loaded \"+work_dir+\"best_\"+checkpointer_name+\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBUe76_NlFi-"
      },
      "source": [
        "'''\n",
        "Record: \n",
        "EMNIST-Digit: AlexNet = 99.21, CapsuleNet = 99.37, VGGNet = 99.62, ResNet = 99.63, ma2019 = 99.75;\n",
        "---\n",
        "\n",
        "#'''\n",
        "\n",
        "result2 = model_loaded.evaluate(final_test_imageset, final_test_label)\n",
        "print(\"nLayers: {}, nNeurons: {}, DROPOUT: {}, Test Acc: {}, Test Loss: {}\".format(NUM_LAYERS, NUM_NEURONS, DROPOUT, round(result2[1], 4), round(result2[0], 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc7lBQw9zE-Y"
      },
      "source": [
        "#elapsed_time = 13273.57\n",
        "\n",
        "with open(work_dir+'Records.csv', \"a\") as fp:\n",
        "    wr = csv.writer(fp, dialect='excel')\n",
        "    wr.writerow([checkpointer_name[8:-5], round(result2[1], 4), round(result2[0], 4), elapsed_time])\n",
        "print(\"Saved results.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I69Rz7U0lz2R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNrrlrUTXYVp"
      },
      "source": [
        "#Confution Matrix and Classification Report\n",
        "Y_pred = model_loaded.predict_generator(final_test_imageset, len(final_test_imageset))\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhiUB_uNXYPL"
      },
      "source": [
        "# Precision [TP/TP+FP] = The ratio of correctly predicted positive observations to the total predicted positive observations.\n",
        "# Recall (Sensitivity) [TP/TP+FN] = The ratio of correctly predicted positive observations to the all observations in actual class - 'yes'.\n",
        "# F1 score [F1 Score = 2*(Recall * Precision) / (Recall + Precision)] = The weighted average of Precision and Recall.\n",
        "# Support = The number of samples of the true response that lie in that class.\n",
        "print('Classification Report:')\n",
        "#target_names = ['Mono', 'Di'] # not ['Di', 'Mono']\n",
        "print(classification_report(y_test, y_pred)) #, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7adZ1XniXYKV"
      },
      "source": [
        "print('Classification Report')\n",
        "print(classification_report(y_test, y_pred, target_names=list_categories))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2woc7B6ClV6G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJjvgOHfkREd"
      },
      "source": [
        "log_data = pd.read_csv(work_dir+log_name, sep=',', engine='python') \n",
        "log_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXvYwRP6lWQz"
      },
      "source": [
        "# Getting the model history keys \n",
        "#history.history.keys()\n",
        "log_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DyZbASblWNn"
      },
      "source": [
        "# plot the training artifacts\n",
        "title = \"Val loss for \"+dataset+\" \"+impl_type+\" (\"+str(NUM_LAYERS)+\" layers, \"+str(NUM_NEURONS)+\" neurons)\"\n",
        "\n",
        "plt.plot(log_data['loss'])\n",
        "plt.plot(log_data['val_loss'])\n",
        "plt.title(title)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss','val_loss'], loc = 'best')\n",
        "\n",
        "img_path = work_dir+'Images/vLoss_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "plt.show()\n",
        "print('img_path =', img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIPNBC_slWKi"
      },
      "source": [
        "title = \"Val acc for \"+dataset+\" \"+impl_type+\" (\"+str(NUM_LAYERS)+\" layers, \"+str(NUM_NEURONS)+\" neurons)\"\n",
        "\n",
        "plt.plot(log_data['accuracy'])\n",
        "plt.plot(log_data['val_accuracy'])\n",
        "plt.title(title)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy','val_accuracy'], loc = 'best')\n",
        "\n",
        "img_path = work_dir+'Images/vAcc_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "plt.show()\n",
        "print('img_path =', img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wxpuYhJlWHI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHcBPAZMlWDz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDC-KGCR9KXu"
      },
      "source": [
        "Image ckeck:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jg6TBJxlV_b"
      },
      "source": [
        "'''\n",
        "Record:\n",
        "EMNIST-Digit: AlexNet = 99.21, VGGNet = 99.62, ResNet = 99.63, CapsuleNet = 99.37, ma2019 = 99.75;\n",
        "dropout = 0.0, Test Acc = 0., Test Loss = 0.;\n",
        "dropout = 0.2, Test Acc = 0.9959, Test Loss = 0.0328;\n",
        "dropout = 0.5, Test Acc = 0.9954, Test Loss = 0.0313;\n",
        "#'''\n",
        "\n",
        "'''\n",
        "DROPOUT = 0.5\n",
        "checkpointer_name  = \"weights_\"+dataset+\"_\"+impl_type+\"_nLayers\"+str(NUM_LAYERS)+\"_nNeurons\"+str(NUM_NEURONS)+\"_dropout\"+str(DROPOUT)+\".hdf5\"\n",
        "log_name = \"log_\"+checkpointer_name[8:-5]+\".log\"\n",
        "log_data = pd.read_csv(work_dir+log_name, sep=',', engine='python') \n",
        "print('log_name =', log_name)\n",
        "###\n",
        "\n",
        "title = \"Val loss for \"+dataset+\" \"+impl_type+\" (\"+str(NUM_LAYERS)+\" layers, \"+str(NUM_NEURONS)+\" neurons)\"\n",
        "plt.plot(log_data['loss'])\n",
        "plt.plot(log_data['val_loss'])\n",
        "plt.title(title)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss','val_loss'], loc = 'best')\n",
        "plt.show()\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQlafPWlXYH5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}